{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# lobrary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                            message\n",
       "0           0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1           1   ham                      Ok lar... Joking wif u oni...\n",
       "2           2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('sms_spam_collection.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method :\n",
    "1. converting to lower case\n",
    "1. contraction\n",
    "1. remove or convert number into text\n",
    "1. remove punctuation\n",
    "1. remove white spaces\n",
    "1. remove stopwords and particular words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apapapapapa'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To lower\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "lower('APAPAPAPAPA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Expand Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall\",\n",
    "\"he'll've\": \"he shall have\",\n",
    "\"he's\": \"he has\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall\",\n",
    "\"I'll've\": \"I shall have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall\",\n",
    "\"it'll've\": \"it shall have\",\n",
    "\"it's\": \"it has\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall\",\n",
    "\"she'll've\": \"she shall have\",\n",
    "\"she's\": \"she has\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall\",\n",
    "\"they'll've\": \"they shall have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall\",\n",
    "\"what'll've\": \"what shall have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall\",\n",
    "\"who'll've\": \"who shall have\",\n",
    "\"who's\": \"who has\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "def main_contraction(text):\n",
    "    text = expand_contractions(text, contractions_dict)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If am not got you'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2 = \"If ain't got you\"\n",
    "main_contraction(text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(text):\n",
    "    output = ''.join(i for i in text if not i.isdigit() )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indonesia agustus \n"
     ]
    }
   ],
   "source": [
    "text_string = \"indonesia 17agustus 1945\"\n",
    "text_string = remove_num(text_string)\n",
    "print(text_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return ''.join(i for i in text if i not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwiki aca ucok kimi\n"
     ]
    }
   ],
   "source": [
    "text_2 = 'dwiki, aca, ucok, kimi'\n",
    "text_2 = remove_punc(text_2)\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ws(text):\n",
    "    return ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apollo launch at 1989\n"
     ]
    }
   ],
   "source": [
    "text_2 = 'apollo      launch  at 1989'\n",
    "text_2 = remove_ws(text_2)\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing Stop Words </h3>\n",
    "- Using NLTK corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english').index('from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(sentence):\n",
    "    stop_words = stopwords.words('english')\n",
    "    return ' '.join([w for w in nltk.word_tokenize(sentence) if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There dwiki , aca , ucok kimi kyah\n"
     ]
    }
   ],
   "source": [
    "text_string = \"There was dwiki, aca, ucok and kimi kyah\"\n",
    "text_string = remove_sw(text_string)\n",
    "print(text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There', 'dwiki', ',', 'aca', ',', 'ucok', 'kimi', 'kyah']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'label', 'message'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>sms_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried contact u u £ pound prize claim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                               sms_prep  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                nah think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried contact u u £ pound prize claim ...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                        pity mood soany suggestions  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sms_prep1'] = data['message'].apply(lower)\n",
    "data['sms_prep2'] = data['sms_prep1'].apply(main_contraction)\n",
    "data['sms_prep3'] = data['sms_prep2'].apply(remove_num)\n",
    "data['sms_prep4'] = data['sms_prep3'].apply(remove_punc)\n",
    "data['sms_prep5'] = data['sms_prep4'].apply(remove_ws)\n",
    "data['sms_prep'] = data['sms_prep5'].apply(remove_sw)\n",
    "\n",
    "data[['label','message','sms_prep']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Stemming and lemmetize</h3>\n",
    "\n",
    "- Stemming increases recall while harming precision\n",
    "- Lemmatize increase precision and harshing recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer('english')\n",
    "\n",
    "def steming(text):\n",
    "    stem_word = [stem.stem(word) for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(text)]\n",
    "    return ' '.join(stem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am read a book and the book is veri fascin'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test ='I am reading a book and the book is very fascinating'\n",
    "steming(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lem(text):\n",
    "    lem_word = [lemma.lemmatize(word) for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(text)]\n",
    "    return ' '.join(lem_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I saw eighteen mouse today !'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test ='I saw eighteen mice today!' \n",
    "lem(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sms_stem'] = data['sms_prep'].apply(steming)\n",
    "data['sms_lem'] = data['sms_prep'].apply(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['sms_lem']\n",
    "y = np.where(data['label'] == 'spam', 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(text, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = CountVectorizer().fit(text_train)\n",
    "x_train = vector.transform(text_train)\n",
    "x_test = vector.transform(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detectorNB = Pipeline([\n",
    "    ('cvt', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvt', CountVectorizer(ngram_range=(1, 2))),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detectorNB.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predNB = spam_detectorNB.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       964\n",
      "           1       0.97      0.92      0.95       151\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x22bfec989a0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(spam_detectorNB, text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hyper Param"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
